{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import math\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('Its Cudaaaaa time')\n",
    "    torch.set_default_device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyper Paramaters\n",
    "\n",
    "K_PULL = 1\n",
    "K_PUSH = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullPE(vector1 : torch.tensor, vector2 : torch.tensor):\n",
    "    distance = torch.linalg.norm(vector1 - vector2)\n",
    "    return (1/2) * K_PULL * (distance ** 2)\n",
    "\n",
    "def pushPE(vector1 : torch.tensor, vector2 : torch.tensor):\n",
    "    distance = torch.linalg.norm(vector1 - vector2)\n",
    "    return -K_PUSH * math.log(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapped_distance(vector1: torch.Tensor, vector2: torch.Tensor):\n",
    "    \"\"\"Calculates the wrapped distance between two points in a periodic space.\"\"\"\n",
    "    dx = torch.abs(vector1[0] - vector2[0])\n",
    "    dy = torch.abs(vector1[1] - vector2[1])\n",
    "    \n",
    "    dx = torch.where(dx > WIDTH / 2, WIDTH - dx, dx)\n",
    "    dy = torch.where(dy > HEIGHT / 2, HEIGHT - dy, dy)\n",
    "    \n",
    "    return torch.sqrt(dx ** 2 + dy ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Check if a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"cudaaaaa\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# Create tensors on the GPU\n",
    "x = torch.randn(1000, 1000, device=device)\n",
    "y = torch.randn(1000, 1000, device=device)\n",
    "\n",
    "# Perform calculations on the GPU\n",
    "z = torch.matmul(x, y)  # This matrix multiplication happens on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "# Set device to GPU if available, otherwise use CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "K_PULL = 1.0  # Adjust this constant as needed for pull force\n",
    "K_PUSH = 1.0  # Adjust this constant as needed for push force\n",
    "DIMENSIONS = 2  # Can be set to any number of dimensions\n",
    "WIDTH, HEIGHT = 1000, 1000  # Dimensions of the square\n",
    "\n",
    "def wrapped_distance(nodes: torch.Tensor):\n",
    "    \"\"\"Calculates the wrapped distance matrix for a batch of nodes in a periodic space.\"\"\"\n",
    "    # Calculate direct differences\n",
    "    dx = nodes[:, None, 0] - nodes[None, :, 0]  # Shape (N, N)\n",
    "    dy = nodes[:, None, 1] - nodes[None, :, 1]  # Shape (N, N)\n",
    "    \n",
    "    # Wrap around for each dimension\n",
    "    dx = torch.where(torch.abs(dx) > WIDTH / 2, WIDTH - torch.abs(dx), torch.abs(dx))\n",
    "    dy = torch.where(torch.abs(dy) > HEIGHT / 2, HEIGHT - torch.abs(dy), torch.abs(dy))\n",
    "    \n",
    "    # Compute the Euclidean distance\n",
    "    return torch.sqrt(dx ** 2 + dy ** 2)\n",
    "\n",
    "def pullPE(distance_matrix: torch.Tensor):\n",
    "    \"\"\"Calculates the potential energy for attracting connected nodes.\"\"\"\n",
    "    return (1/2) * K_PULL * (distance_matrix ** 2)\n",
    "\n",
    "def pushPE(distance_matrix: torch.Tensor):\n",
    "    \"\"\"Calculates the potential energy for repelling unconnected nodes.\"\"\"\n",
    "    # Use torch.log to avoid log(0) for distances\n",
    "    with torch.no_grad():\n",
    "        return -K_PUSH * torch.log(distance_matrix + 1e-8)  # Adding small value to avoid log(0)\n",
    "\n",
    "def calculateTotalEnergy(nodes: torch.Tensor, edges: list):\n",
    "    \"\"\"Calculates the total potential energy for the graph.\"\"\"\n",
    "    total_energy = torch.tensor(0.0, device=device)  # Initialize on the correct device\n",
    "    distance_matrix = wrapped_distance(nodes)  # Shape (N, N)\n",
    "\n",
    "    for i in range(len(nodes)):\n",
    "        for j in range(len(nodes)):\n",
    "            if i != j:\n",
    "                if (i, j) in edges or (j, i) in edges:  # Check if there's an edge\n",
    "                    total_energy += pullPE(distance_matrix[i, j])\n",
    "                else:\n",
    "                    total_energy += pushPE(distance_matrix[i, j])\n",
    "\n",
    "    return total_energy\n",
    "\n",
    "# Example usage\n",
    "nodes = torch.tensor([\n",
    "    [100.0, 100.0],\n",
    "    [900.0, 100.0],\n",
    "    [500.0, 900.0],\n",
    "    [150.0, 850.0],\n",
    "], device=device)\n",
    "\n",
    "edges = [(0, 1), (1, 2), (2, 0)]  # Example edges connecting nodes\n",
    "\n",
    "total_energy = calculateTotalEnergy(nodes, edges)\n",
    "print(\"Total Energy:\", total_energy.item()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "# Set device to GPU if available, otherwise use CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "K_PULL = 1.0  # Adjust this constant as needed for pull force\n",
    "K_PUSH = 1.0  # Adjust this constant as needed for push force\n",
    "\n",
    "# Dimensions of the space (can be set to any number)\n",
    "DIMENSIONS = 3\n",
    "BOUNDARIES = [1000] * DIMENSIONS  # Example boundaries for each dimension (1000 for each)\n",
    "\n",
    "def wrapped_distance(nodes: torch.Tensor):\n",
    "    \"\"\"Calculates the wrapped distance matrix for a batch of nodes in a periodic space.\"\"\"\n",
    "    # Compute differences for all pairs of nodes using broadcasting\n",
    "    diff = nodes[:, None, :] - nodes[None, :, :]  # Shape (N, N, DIMENSIONS)\n",
    "\n",
    "    # Apply wrap-around for each dimension\n",
    "    for dim in range(DIMENSIONS):\n",
    "        abs_diff = torch.abs(diff[:, :, dim])  # Shape (N, N)\n",
    "        abs_diff = torch.where(abs_diff > BOUNDARIES[dim] / 2, BOUNDARIES[dim] - abs_diff, abs_diff)\n",
    "        diff[:, :, dim] = abs_diff  # Update the difference with wrapped distances\n",
    "\n",
    "    # Compute the Euclidean distance across all dimensions\n",
    "    return torch.sqrt(torch.sum(diff ** 2, dim=-1))  # Shape (N, N)\n",
    "\n",
    "def pullPE(distance_matrix: torch.Tensor):\n",
    "    \"\"\"Calculates the potential energy for attracting connected nodes.\"\"\"\n",
    "    return (1/2) * K_PULL * (distance_matrix ** 2)\n",
    "\n",
    "def pushPE(distance_matrix: torch.Tensor):\n",
    "    \"\"\"Calculates the potential energy for repelling unconnected nodes.\"\"\"\n",
    "    # Use torch.log to avoid log(0) for distances\n",
    "    with torch.no_grad():\n",
    "        return -K_PUSH * torch.log(distance_matrix + 1e-8)  # Adding small value to avoid log(0)\n",
    "\n",
    "def calculateTotalEnergy(nodes: torch.Tensor, edges: list):\n",
    "    \"\"\"Calculates the total potential energy for the graph.\"\"\"\n",
    "    total_energy = torch.tensor(0.0, device=device)  # Initialize on the correct device\n",
    "    distance_matrix = wrapped_distance(nodes)  # Shape (N, N)\n",
    "\n",
    "    for i in range(len(nodes)):\n",
    "        for j in range(len(nodes)):\n",
    "            if i != j:\n",
    "                if (i, j) in edges or (j, i) in edges:  # Check if there's an edge\n",
    "                    total_energy += pullPE(distance_matrix[i, j])\n",
    "                else:\n",
    "                    total_energy += pushPE(distance_matrix[i, j])\n",
    "\n",
    "    return total_energy\n",
    "\n",
    "# Example usage\n",
    "nodes = torch.tensor([\n",
    "    [100.0, 100.0, 50.0],\n",
    "    [900.0, 100.0, 800.0],\n",
    "    [500.0, 900.0, 200.0],\n",
    "    [150.0, 850.0, 100.0],\n",
    "], device=device)\n",
    "\n",
    "edges = [(0, 1), (1, 2), (2, 0)]  # Example edges connecting nodes\n",
    "\n",
    "total_energy = calculateTotalEnergy(nodes, edges)\n",
    "print(\"Total Energy:\", total_energy.item()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  0,  0],\n",
      "         [-3, -3, -3],\n",
      "         [-8, -6, -4],\n",
      "         [-9, -9, -9]],\n",
      "\n",
      "        [[ 3,  3,  3],\n",
      "         [ 0,  0,  0],\n",
      "         [-5, -3, -1],\n",
      "         [-6, -6, -6]],\n",
      "\n",
      "        [[ 8,  6,  4],\n",
      "         [ 5,  3,  1],\n",
      "         [ 0,  0,  0],\n",
      "         [-1, -3, -5]],\n",
      "\n",
      "        [[ 9,  9,  9],\n",
      "         [ 6,  6,  6],\n",
      "         [ 1,  3,  5],\n",
      "         [ 0,  0,  0]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "nodes = torch.tensor([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [9, 8, 7],\n",
    "    [10, 11, 12]\n",
    "])\n",
    "\n",
    "diff = nodes[:, None, :] - nodes[None, :, :]\n",
    "\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Create a COO sparse tensor\n",
    "indices = torch.tensor([[0, 1, 1],\n",
    "                        [2, 0, 2]])  # (row indices, col indices)\n",
    "values = torch.tensor([3, 4, 5], dtype=torch.float32)\n",
    "size = torch.Size([3, 3])\n",
    "\n",
    "# Create sparse tensor\n",
    "sparse_matrix = torch.sparse_coo_tensor(indices, values, size)\n",
    "\n",
    "# Convert to dense for inspection\n",
    "dense_matrix = sparse_matrix.to_dense()\n",
    "print(dense_matrix)\n",
    "\n",
    "# Perform matrix-vector multiplication\n",
    "vector = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
    "result = torch.sparse.mm(sparse_matrix, vector.unsqueeze(1))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparsity Threshold\n",
    "Sparse matrices are most beneficial when thereâ€™s a high proportion of zero entries. If the matrix is too dense, using a sparse format could lead to worse performance due to the overhead of managing the sparse structure. As a rule of thumb:\n",
    "\n",
    "Use sparse matrices if more than ~50-70% of the matrix elements are zeros.\n",
    "\n",
    "Analyze density to determine if a spare represntation would be a good idea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Reduce Memory Usage\n",
    "In-Place Operations: When possible, use in-place operations to avoid unnecessary memory allocations, which can slow down computations.\n",
    "\n",
    "Memory Efficient Data Types: If precision allows, use lower precision (e.g., torch.float16 or torch.float32 instead of torch.float64) to save memory and increase speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/calculating-derivatives-in-pytorch/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "songs = {1,2}\n",
    "connections = {}\n",
    "\n",
    "for playlist in data['playlists']:\n",
    "    for idx, track in enumerate(playlist['tracks']):\n",
    "        \n",
    "        if not (track['artist_name'] in songs):\n",
    "            songs.add('artist_name')\n",
    "        for i in range(idx+1,len(playlist['tracks'])):\n",
    "            connection = track['artist_name'] + \":::\" + playlist['tracks'][i]['artist_name']\n",
    "            if connection in connections:\n",
    "                connections[connection] += 1\n",
    "            else:\n",
    "                connections[connection]  = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = torch.tensor([[0, 0, 0], [0, 3, 0], [0, 0, 4]])\n",
    "#sparse_tensor = dense_tensor.to_sparse()\n",
    "\n",
    "\n",
    "diff = nodes[:, None, :] - nodes[None, :, :]\n",
    "\n",
    "sparse_tensor = diff.to_sparse()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "cords = [[random.random(),random.random(),random.random()] for _ in range(10000000)]\n",
    "weights = [random.random() for _ in range(10000000)]\n",
    "\n",
    "print(calculateForce(torch.tensor([cords]),torch.tensor(weights)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
